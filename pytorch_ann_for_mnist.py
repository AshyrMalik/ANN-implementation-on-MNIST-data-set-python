# -*- coding: utf-8 -*-
"""Pytorch: ANN for MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZboKH_d1MLrI8SlaYOaMgbmMTGW4es1K
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt

train_dataset=torchvision.datasets.MNIST(root='.',
                                         train=True,
                                         transform=transforms.ToTensor(),
                                         download=True)

train_dataset.data

train_dataset.data.shape

train_dataset.targets

test_dataset=torchvision.datasets.MNIST(root='.',
                                         train=False,
                                         transform=transforms.ToTensor(),
                                          download= True)

model = nn.Sequential(
    nn.Linear(784,128),
    nn.ReLU(),
    nn.Linear(128,10)
)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
model.to(device)

criterion= nn.CrossEntropyLoss()
optimizer= torch.optim.Adam(model.parameters())

batch_size = 128

# DataLoader for the training dataset
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)

# DataLoader for the test dataset
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

no_of_epochs= 10

train_losses= np.zeros(no_of_epochs)
test_losses= np.zeros(no_of_epochs)

for it in range (no_of_epochs):
  train_loss=[]
  for inputs,targets in train_loader:
    inputs= inputs.to(device)
    targets= targets.to(device)

    input = inputs.view(-1,784)
    optimizer.zero_grad()
    outputs= model(input)
    loss= criterion(outputs,targets)

    loss.backward()
    optimizer.step()

    train_loss.append(loss.item())

  test_loss=[]
  for inputs,targets in test_loader:
    inputs= inputs.to(device)
    targets= targets.to(device)
    inputs = inputs.view(-1, 784)
    outputs= model(inputs)
    loss= criterion(outputs,targets)
    test_loss.append(loss.item())

  train_losses[it]= np.mean(train_loss)
  test_losses[it]= np.mean(test_loss)

  print(f"Epoch {it+1}/{no_of_epochs}, Train Loss: {train_losses[it]:.4f}, Test Loss: {test_losses[it]:.4f}")

import matplotlib.pyplot as plt

# Plot losses
plt.figure(figsize=(8, 6))  # Optional: Adjust figure size for better visualization
plt.plot(train_losses, label='Train Loss', marker='o')  # Add markers for clarity
plt.plot(test_losses, label='Test Loss', marker='s')
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.title('Training and Testing Loss Over Epochs', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True)  # Optional: Add grid for better readability
plt.show()

# Initialize counters for training accuracy
c_total = 0
n_total = 0

# Training accuracy calculation
model.eval()  # Set model to evaluation mode
with torch.no_grad():  # Disable gradient computation
    for inputs, targets in train_loader:
        # Move data to the device
        inputs, targets = inputs.to(device), targets.to(device)

        # Reshape inputs if necessary
        inputs = inputs.view(-1, 784)

        # Forward pass
        outputs = model(inputs)

        # Get predictions (class with the highest probability)
        _, predictions = torch.max(outputs, 1)

        # Count correct predictions
        c_total += (predictions == targets).sum().item()
        n_total += targets.size(0)

train_accuracy = c_total / n_total

# Initialize counters for test accuracy
c_total = 0
n_total = 0

# Testing accuracy calculation
with torch.no_grad():  # Disable gradient computation
    for inputs, targets in test_loader:
        # Move data to the device
        inputs, targets = inputs.to(device), targets.to(device)

        # Reshape inputs if necessary
        inputs = inputs.view(-1, 784)

        # Forward pass
        outputs = model(inputs)

        # Get predictions
        _, predictions = torch.max(outputs, 1)

        # Count correct predictions
        c_total += (predictions == targets).sum().item()
        n_total += targets.size(0)

test_accuracy = c_total / n_total

# Print accuracies
print(f"Train Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

